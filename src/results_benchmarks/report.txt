
\section*{MATRIX IMPLEMENTATION}

In order to perform the operations described above, a custom \texttt{Matrix} class has been developed.

The class is generic with respect to the type saved in the matrix (preferably a floating point), and it has another template parameter which is the ordering, either row-major or col-major.

The decision of the ordering is done at compile time, so the implementation has the choice to select the best implementation with no overhead at runtime.

The \texttt{FullMatrix} class has been developed in parallel with all the algorithms, so the first implementation contained the matrix classes provided by the Eigen library.

In order to avoid the rewriting of the code, all the methods provided by the \texttt{FullMatrix} class have been created to emulate most of the Eigen functionalities. Indeed, if a particular method was utilized from the \texttt{Eigen::MatrixXd} class, it would appear a few days later also in the \texttt{FullMatrix} class.

\textbf{Note:} most of the functionalities are mirrored, but some could not be exactly replicated due to the inherently different structure (and surely, more complex) of the Eigen library. So in some parts of the code, there is a preprocessor directive:

\begin{verbatim}
#ifdef EIGEN

// Eigen::MatrixXd

#else 

// FullMatrix

#endif
\end{verbatim}

\textbf{Note:} Eigen uses another class for the definition of a vector, indeed \texttt{Eigen::VectorXd}. But the \texttt{FullMatrix} class can be also used as a vector; indeed, in the file \texttt{utils.hpp} there is:

\begin{verbatim}
using Vector = FullMatrix<Real, ORDERING::ROWMAJOR> // Real is a double
\end{verbatim}

\textbf{Remember:} there is an overload of the constructor of \texttt{FullMatrix} defined as

\begin{verbatim}
FullMatrix(const size_t n): FullMatrix(n,1) {}
\end{verbatim}

which creates a column vector.

So the accessing can be performed both in a matrix way, using the \texttt{operator()}, and in a vector way, using the \texttt{operator[]}.


\section*{TRANSPOSITION}

The first implementation, when calling the method \texttt{transpose()}, would return a copy of the matrix but with the entries rearranged in order to satisfy the transposition.

This, of course, is not a good implementation since we are creating another matrix with all the information already present in the original one. With just one change of perspective, we can achieve much better performances.

Indeed, a class \texttt{FullMatrixAdjoint} has been developed that contains a reference to a \texttt{FullMatrix} object. When calling the access operators on a \texttt{FullMatrixAdjoint} object, it returns the elements in the matrix but from a transposed point of view (everything is mirrored with respect to the original object).

Note that this class is not a child of a \texttt{FullMatrix}, but a wrapper. This decision was made because conceptually a parent should not call methods that return its child, which happens in the \texttt{transpose()} method. But, of course, this decision has its disadvantages, since each method has to be re-declared from scratch (here in the class only the necessary methods have been developed).

The more correct solution would be similar to the Eigen implementation, each matrix class should derive from a superclass (called \texttt{MatrixBase} in Eigen) where most of the methods are defined.

Small note: there is some code repetition in the matrix class, since the matrix multiplication needs to be specified for matrix-transposed and the reverse, and for transposed-expression and reverse.

A better solution is to perform a partial specialization of the method with a concept (defined for matrix and its transposed), but there was a problem since I could not create a concept for the \texttt{FullMatrixTransposed} class. The type should be something along the lines of \texttt{FullMatrix<Real, ORDERING>::FullMatrixAdjoint}, but no matter the template I created, the compiler continued to give an error for the type declaration of the class.

\section*{MULTIPLICATION}

The matrix can perform most of the classical component-wise operations (see section on lazy evaluation) and row-column operations.

Then the most expensive operation with matrices is the matrix-matrix multiplication, and here we briefly discuss some results.

The operation has been constructed following the article: \url{https://siboehm.com/articles/22/Fast-MMM-on-CPU}. Almost everything described has been implemented, except for the tiling of the operation.

The implementation is different for row-major and col-major matrices, and for both cases, it tries to exploit completely cache coherency and SIMD operations.

The results below show the performance of the matrix-matrix multiplication for increasing sizes of the matrices, both without compiler optimization and with the flags \texttt{"-O3 -march=native"} activated.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{matmult_noopt.png}
    \caption{Photo of matmult\_noopt.png}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{matmult_opt.png}
    \caption{Photo of matmult\_opt.png}
\end{figure}

Here we can notice two main properties:

\begin{itemize}
    \item the optimizer does a lot of work (for \(N=1000\) we get approximately 70x speedup).
    \item up until approximately \(N=1600\) the OpenMP implementation keeps the pace with Eigen (which has also OpenMP beneath), but after that, there is a huge loss in performance, since the implementation does not perform tiling and the matrices are too big to fit in a single page of the cache.
\end{itemize}

\section*{LAZY EVALUATION}

The matrix can also perform component-wise operations in a lazy way, by setting the compilation flag \texttt{"-DLAZY"}.

The pattern used is the CRTP (curiously recursive template pattern) of the expression templates, described extensively [here](https://link.springer.com/article/10.1007/s00791-009-0128-2).

This pattern helps construct an expression class at compile time that contains the expression tree evaluated by the compiler. Indeed, each class derives from a superclass \texttt{Expr<T>} recursively in the following way:

\begin{verbatim}
public class C : Expr<C> {…}
\end{verbatim}

There was also the possibility to construct lazily the row-column product, but this implementation was held back mainly by two major problems:

\begin{itemize}
    \item the optimization for cache-friendly accesses would require the multiplication operator (defined as a functor) to know about the ordering of the matrix at compile time and to reorder the operations accordingly.
    \item there is a major problem when performing an operation such as:

    \begin{verbatim}
    FullMatrix a;

    a = a * a; // Assuming that a is squared
    \end{verbatim}

    If the operation is performed in a lazy way, the result will, of course, not be correct starting from the second term computed in the matrix.

    An alternative solution then would require understanding at compile time if a matrix is present both in the lhs and the rhs of the operation, but the solution is not trivial and requires traversing the expression tree recursively at compile time.

    A simpler solution could also be to create a temporary each time the multiplication operator between matrices (or expressions of matrices) is called, but this is exactly what is done without expression templates. This would also not impact the performance much since creating a matrix is less costly than performing a multiplication.

    So in the end this operation was kept without lazy evaluation.
\end{itemize}

\textbf{Note:} the same problem emerges when doing an operation such that

\begin{verbatim}
a = a + (or -) a.transpose();
\end{verbatim}

Which returns the symmetric (or skew-symmetric) part of a matrix, but since it is not required from the application it was not addressed.

The tests in order to understand the improvements were performed on 5 different operations, both in a lazy and non-lazy way, all with the optimization flags enabled:

\begin{itemize}
    \item \texttt{c = a + b; // SUM\_SHORT}
    \item \texttt{c = a + b + a + b + a + b + a + b + a + b; // SUM\_LONG}
    \item \texttt{c = a * 2.; // PROD\_SHORT}
    \item \texttt{c = a * 2. * 2. * 2. * 2. * 2. * 2. * 2. * 2. * 2.; // PROD\_LONG}
    \item \texttt{c = a * (a + b * 2.) * a.transpose(); // MIXED}
\end{itemize}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{sumshort_lazy.png}
    \caption{Photo of sumshort\_lazy.png}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{sumshort_nolazy.png}
    \caption{Photo of sumshort\_nolazy.png}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{sumlong_lazy.png}
    \caption{Photo of sumlong\_lazy.png}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{sumlong_nolazy.png}
    \caption{Photo of sumlong\_nolazy.png}
\end{figure}

Here we can see that using lazy evaluation on the sum of matrices has a huge impact since for the long operation the speedup reaches 25x.

Now since this operation is not very realistic, we can see that only with a small operation we get an approximate 2.5x speedup, and since is just 1 against the 9 sums of before, the results are expected (we create 9 temporaries and do a last assignment -> 10 operations in total).

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{prodshort_lazy.png}
    \caption{Photo of prodshort\_lazy.png}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{prodshort_nolazy.png}
    \caption{Photo of prodshort\_nolazy.png}
\end{figure}

Also for the product of multiple scalars, we get a similar speedup, this time is actually higher since we have to do fewer accesses to the memory because we work only with one matrix.

Interestingly, we can see that for the lazy product, an OpenMP implementation gives some performance increase, not much but it is still approximately a 1.1x speedup.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{mixed_nolazy.png}
    \caption{Photo of mixed\_nolazy.png}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{mixed_lazy.png}
    \caption{Photo of mixed\_lazy.png}
\end{figure}

For a mixed operation, we can see that the graph very much resembles the matrix-matrix multiplication, just with a lot more time since now we perform 3 multiplications.

So if we would like an improvement from the timing perspective, we would need to increase much more the size of the lazy expression, but it is not realistic since it is not in any of the algorithms implemented. But at least there is an improvement in memory usage, since fewer temporaries are created.

\section*{BENCHMARKS}

The specifics of my computer are the following:

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{my_specs.png}
    \caption{Photo of my\_specs.png}
\end{figure}

All the tests are performed using a benchmark that executes the operations a bunch of times for different sizes of the matrices.

Then the best-performing time (the fastest) is kept after all the tests have been done and stored in a CSV file.

The formula for how many iterations have to be performed is the following exponential:

\[
\text{times} = \text{floor}(2. + (\text{end} – 2.) \times \exp\left(

where \(i\) is the current dimension of the matrix, \(\text{{start}}\) is the initial dimension, \(\text{{end}}\) is the final dimension, and \(\tau\) is a constant decided differently for each operation.

\textbf{Small note:} In the code, there is also a linear interpolator and a cubic interpolator, but the cubic does not work well, and the linear does not reflect well the difference in time/size with the matrix multiplication (since it grows as a cubic function).

\section*{For the Future}

There are other possibilities for growing the project even more. Here are some ideas:

\begin{itemize}
    \item Doing tiling in matrix-matrix multiplications (or even using GPUs, with CUDA).
    \item Completing the section on lazy evaluations by adding the lazy row-column product where the decision of storing it in a temporary or not is performed at compile time.
    \item Introducing lazy evaluation with ranges: in this [article](https://gieseanw.wordpress.com/2019/10/20/we-dont-need-no-stinking-expression-templates/), there is an informal description of how we can perform lazy evaluation with one of the newest introductions in C++, the ranges. It shows also how to perform matrix-vector multiplication, but the matrix was stored in a 2D array. An interesting starting point would be the function \texttt{std::ranges::view::chunk} and \texttt{chunk\_view} (described [here](https://en.cppreference.com/w/cpp/ranges/chunk_view)) to split the 1D vector into chunks of equal size. However, this implementation requires C++ 23, which is only supported by the newest compiler versions, and we would need to change all the versions of our current compiler. I personally do not think that we can get any substantial improvement with respect to the expression templates implementation, but it can be very interesting to study a more "functional" and modern approach to the problem, since there is not a lot of literature on this topic yet.
\end{itemize}

\documentclass{article}

\usepackage{amsmath}
\usepackage{geometry}
\usepackage{listings}
\usepackage{color}
\usepackage{listings}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{graphicx}
\graphicspath{{images/}}
\usepackage{subfigure}
\usepackage[utf8]{inputenc}
\usepackage{graphicx} %LaTeX package to import graphics
\graphicspath{{images/}} %configuring the graphicx package
\usepackage[export]{adjustbox}
\usepackage{subfigure}
\usepackage{amsmath}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\DeclareMathOperator{\sign}{sign}
\usepackage[a4paper, total={6in, 8in}]{geometry}

\setcounter{section}{-1}

% Define colors for code highlighting
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

% Define code listing style
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

% Set code listing style
\lstset{style=mystyle}

\geometry{a4paper, margin=1in}

\begin{document}

\title{QR Factorization Report}
\author{Your Name}
\date{\today}
\maketitle


\section{Introduction}

QR factorization is a fundamental numerical technique used in linear algebra to decompose a matrix into the product of an orthogonal matrix and an upper triangular matrix. This factorization plays a crucial role in various applications, including solving systems of linear equations, least squares problems, and eigenvalue computations.

The decomposition of a matrix $A$ into the product $A = QR$ involves obtaining an orthogonal matrix $Q$ and an upper triangular matrix $R$. The orthogonal matrix $Q$ captures the rotation and reflection components, while the upper triangular matrix $R$ contains the essential information about the original matrix.

In this report, we delve into the QR factorization process, specifically focusing on two distinct algorithms: the Givens rotation and the Householder reflection. These algorithms provide numerical methods to transform a given matrix into its QR factorization, each with its unique approach to introducing zeros below the main diagonal.

The Givens algorithm employs sequential rotations to eliminate elements below the diagonal, while the Householder algorithm uses successive reflections to achieve a similar result.

In the subsequent sections, we provide an in-depth overview of our version of the Givens and Householder algorithms, discussing their implementation details, computational considerations, and performance characteristics.


\section{Overview of Givens Algorithm}

The Givens algorithm is a numerical technique used for QR factorization. The Givens rotation is employed to introduce zero elements below the diagonal of the matrix, gradually transforming it into its triangular form.
\begin{algorithm}
\caption{Givens QR Factorization}
\begin{algorithmic}[1]
\Procedure{GivensQR}{$A$}
    \State $m, n \gets \text{dimensions of } A$
    \State Initialize $Q$ as identity matrix
    \State $R \gets A$
    
    \For{$j \gets 1$ \textbf{to} $n$}
        \For{$i \gets m$ \textbf{downto} $j+1$}
            \State Compute Givens rotation parameters $c, s$ for $R(i-1, j), R(i, j)$
            \State Apply Givens rotation to update $R$ and $Q$
        \EndFor
    \EndFor
    
    \State \textbf{return} $Q, R$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Parallelization}


\subsubsection{Givens Algorithm with OpenMP}

The OpenMP implementation of the Givens algorithm effectively parallelizes computations across multiple threads. This approach involves parallelizing the outer loop over matrix columns (\(j\)), enabling concurrent computation on independent columns. Thread-specific variables, including \(c\), \(s\), \(a\), \(b\), and \(tmp\), are marked as private to ensure thread safety and prevent potential data races. The use of \texttt{\#pragma omp single} guarantees that critical initial calculations are executed by a single thread, avoiding race conditions. Atomic addition (\(tmp = 0.0;\)) is employed to prevent data races when updating shared variables within the parallel region. Computation on matrices \(Q\) and \(R\) is efficiently integrated within the parallel region, eliminating the need for additional synchronization mechanisms.

\subsubsection{Givens Algorithm with MPI}

The MPI implementation of the Givens algorithm adopts a distributed computing approach, distributing matrix columns across multiple processes. This is achieved by leveraging the message passing property of MPI. Each process iterates over different columns and starts executing only after the \((j-1)\)-th column has computed the \((m-1)\)-th and \((m-2)\)-th rows. This is shown in {figure}[h] .



Synchronization of the computation involves exchanging flags (\texttt{syncflag}) to coordinate the execution among processes. The use of \texttt{MPI\_Scatterv} efficiently distributes portions of the original matrix (\(R\)) to each process. This operation is particularly effective in minimizing communication overhead and ensuring efficient data movement. Similarly, \texttt{MPI\_Gatherv} is employed to collect the results from each process and reconstruct the final matrix, completing the distributed computation.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{Applying-Givens-rotations-in-parallel.jpg}
    \caption{Visualization of the MPI Givens algorithm.}
    \label{fig:mpi_givens}
\end{figure}



\subsection{General Observations and Recommendations}

Both implementations exhibit a noticeable speedup starting from an average matrix size of 100 when executed on a standard PC with the specifications attached at the end of the report.

The MPI approach theoretically aims for a speedup of \( \frac{n}{2} \), although the actual achieved speedup is likely lower due to the substantial overhead introduced by message passing. Despite this, the MPI implementation demonstrates superior scalability compared to the OpenMP approach.

Below are the presented results:

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{grafico.pdf}
    \caption{Speedup comparison between MPI and OpenMP implementations.}
    \label{fig:speedup_comparison}
\end{figure}

These results highlight a significant improvement in performance, particularly for larger matrix sizes. The MPI approach showcases a more scalable behavior, confirming its suitability for parallelizing the Givens algorithm.



\subsection{Results and Performance}
The implementation avoids explicitly constructing the Givens rotation matrix and directly computes the changes to matrices $Q$ and $R$ during each iteration. This approach can be computationally efficient, especially for large matrices.



\section{Overview of Householder Algorithm}

The Householder algorithm is another numerical technique used for QR factorization, a process that decomposes a matrix into the product of an orthogonal matrix (Q) and an upper triangular matrix (R). Similar to the Givens algorithm, the Householder transformation is employed to introduce zero elements below the diagonal of the matrix.

In the implementation provided, the Householder algorithm is applied to a given matrix $A$ to obtain its QR factorization, where $Q$ is an orthogonal matrix and $R$ is an upper triangular matrix.

\begin{algorithm}
\caption{Householder QR Factorization}
\begin{algorithmic}[1]
\Procedure{HouseholderQR}{$A$}
    \State $m, n \gets \text{dimensions of } A$
    \State Initialize matrices $Q$ and $R$
    \State $Q \gets I_m$ \tcp{Initialize $Q$ as identity matrix}
    \State $R \gets A$
    
    \For{$j \gets 1$ \textbf{to} $\min(m, n)$}
        \State Compute Householder vector $v$ from $R(j:m, j)$
        \State Compute Householder transformation matrix $P$
        \State Update $R$ and $Q$ using $P$
    \EndFor
    
    \State \textbf{return} $Q, R$
\EndProcedure
\end{algorithmic}
\end{algorithm}


\subsection{Parallelization}
The parallelized Householder QR factorization algorithm begins by initializing matrices for orthogonal transformations \([Q]\), rotation matrices \([P]\), and the input matrix \([R]\). It employs OpenMP parallelization to enhance efficiency, distributing the computation of vectors and matrices across multiple threads. The algorithm iteratively computes Householder vectors, transforming the input matrix into upper triangular form. The computed orthogonal transformations \([Q]\) and upper triangular matrix \([R]\) are updated concurrently within parallel sections, exploiting parallelism for accelerated computation. To improve numerical stability, the algorithm normalizes the Householder vectors and applies the transformations to the input matrix. Additionally, a parallel loop efficiently zeroes out the lower triangular portion of the resulting upper triangular matrix. The algorithm utilizes critical sections to ensure correct matrix updates within parallel regions.

\subsection{General Observations and Recommendations}
Such implementation exhibits a good speedup, as shown in the figure below.



\section{Computational Considerations}
One can assert that, in general, for dense matrices, it is advantageous to use the Householder algorithm for QR factorization. On the other hand, if the matrix to be factorized already has many zero diagonals below the main diagonal, then the Givens algorithm may be more convenient from a computational perspective. This is based on both the reduced computation time and the fewer number of operations performed. The choice between Householder and Givens algorithms is influenced by the matrix structure and the specific requirements of the computation. Householder transformations are preferred for their numerical stability and efficiency in handling dense matrices, while Givens rotations are advantageous when dealing with matrices exhibiting sparsity, particularly with many zero diagonals below the main diagonal. Choosing the Givens algorithm is advantageous for scenarios that demand sparsity preservation, numerical stability, and incremental updates, but careful consideration is necessary for optimal performance in specific problem contexts.


\newpage

\section*{Image Compression}
\setcounter{section}{0}
\section{Introduction}
Images can be represented through three color channels: red, green, and blue, each as a $(m \times n)$ matrix with values ranging from 0 to 255. Alternatively, images can be in grayscale, where each pixel is represented by a single intensity value. In the context of compression, we will focus on compressing the matrices representing individual color channels.

To compress a matrix $A$, we seek an approximation requiring significantly less storage space. Singular Value Decomposition (SVD) proves advantageous for this purpose. SVD decomposes $A$ into three matrices, $U$, $\Sigma$, and $V$, ordered by their contributions to $A$. This ordering facilitates efficient approximation by retaining only the most significant components of these matrices.

For compression, a parameter $k$ is chosen to determine the number of singular values considered for the approximation. A higher $k$ improves approximation quality but also increases the data required for encoding. The compression process involves selecting only the first $k$ columns of matrices $U$ and $V$, and the upper-left $(k \times k)$ square of $\Sigma$, which contains the $k$ largest (and therefore most important) singular values. Additionally, the oversampling factor $p$ can be added to retrieve addiditional information. 

It's worth noting that a similar approach can be employed for grayscale images, where the compression is achieved through the decomposition of a single intensity matrix. This versatility allows for an efficient compression strategy that adapts to both color and grayscale representations.

\section{Overview of Image Compression algorithm}
The C++ code utilizes Singular Value Decomposition (SVD) for image compression, setting parameters for rank ($r$) and oversampling ($p$). It loads a PNG image using the STB library, instantiates the `APPLICATIONS` class, and measures compression time. The code adapts to RGB or grayscale, applying SVD-based compression accordingly. After compression, a backward conversion restores the image. Key metrics like uncompressed size, compressed size, ratio, and duration are computed. The decompressed image is saved, and memory is freed. The pseudocode succinctly outlines these steps in the \texttt{main} function.
\begin{algorithm}
\caption{Main Function for Image Compression}
\begin{algorithmic}[1]
\Procedure{main}{}
    \State Set compression parameters $r$ and $p$
    \State Set input and output file paths
    \State Load input image from file
    \If{RGB image}
        \For{each color channel}
            \State Perform image compression using rSVD
            \State Perform backward conversion to obtain decompressed image
        \EndFor
    \Else
        \State Perform image compression using rSVD (grayscale)
        \For{each color channel}
            \State Perform backward conversion to obtain decompressed image
        \EndFor
    \EndIf
    \State Save decompressed image to file
    \State Free allocated memory
    \State \textbf{return} 0
\EndProcedure
\end{algorithmic}
\end{algorithm}

\section{Testing and results}
Testing was done for the nicest and most wellness picture in the entire world.

\end{document}
